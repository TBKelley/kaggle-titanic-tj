{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load libraries and set up graphing, load data sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from pylab import rcParams, gray\n",
      "import numpy as np\n",
      "from pandas import read_csv \n",
      "\n",
      "rcParams['figure.figsize'] = 10, 7.5\n",
      "rcParams['axes.grid'] = True\n",
      "gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x856d278>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = read_csv('../../../data/original/train.csv')\n",
      "test1 = read_csv('../../../data/original/test.csv')\n",
      "test2 = read_csv('../../../data/processed/Test_WithSurvived.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clean data\n",
      "----------\n",
      "### mean removal and variance scaling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td> NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td> C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 12 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "\n",
        "   Parch     Ticket     Fare Cabin Embarked  \n",
        "0      0  A/5 21171   7.2500   NaN        S  \n",
        "1      0   PC 17599  71.2833   C85        C  \n",
        "\n",
        "[2 rows x 12 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Documentation](http://scikit-learn.org/stable/modules/preprocessing.html) for the below code.\n",
      "\n",
      "Perform this for `Fare` and `Age` fields, the only continuous data in the data set. Process the entire dataset, later use `oob_score=True` for RandomForestClassifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import izip\n",
      "\n",
      "\n",
      "def mf(x):\n",
      "    if x == 'male':\n",
      "        return 0\n",
      "    elif x == 'female':\n",
      "        return 1\n",
      "    else:\n",
      "        return 1\n",
      "\n",
      "def pclass(x):\n",
      "    if x == 1:\n",
      "        return 0\n",
      "    elif x == 2:\n",
      "        return 1\n",
      "    elif x == 3:\n",
      "        return 2\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      "def embarked(x):\n",
      "    if x == 'S':\n",
      "        return 0\n",
      "    elif x == 'C':\n",
      "        return 1\n",
      "    elif x == 'Q':\n",
      "        return 2\n",
      "    else:\n",
      "        return 0\n",
      "    \n",
      "def title(x):\n",
      "    s = {\n",
      "         'Master': 0,\n",
      "         'Miss': 1,\n",
      "         'Mrs': 2,\n",
      "         'Mr': 3,\n",
      "         'Dr': 4,\n",
      "         'Capt': 5,\n",
      "         'Don': 5,\n",
      "         'Major': 5,\n",
      "         'Sir': 5,\n",
      "         'Dona': 6,\n",
      "         'Lady': 6,\n",
      "         'the Countess': 6, \n",
      "         'Jonkheer': 6\n",
      "         }\n",
      "    for k in s.keys():\n",
      "        if k in x:\n",
      "            return s[k]\n",
      "    return 7\n",
      "\n",
      "def impute(x, means):\n",
      "    if isnull(x['Age']) and not isnull(x['Title']):\n",
      "        return means[x['Title']]\n",
      "    elif isnull(x['Age']):\n",
      "        return means.mean()\n",
      "    else:\n",
      "        return x['Age']\n",
      "\n",
      "#ticket = dict(izip(train.Ticket.unique(), xrange(len(train.Ticket.unique())))) #len=680\n",
      "#cabin = dict(izip(train.Cabin.unique(), xrange(len(train.Cabin.unique())))) #len=147"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# test\n",
      "from pandas import cut\n",
      "r = range(int(np.floor(min(X_cont[0::,0]))), int(np.ceil(max(X_cont[0::,0]))), 1)\n",
      "cut(X_cont[0::,0], r, labels=r[:-1], include_lowest=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'X_cont' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-66689a0d4f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cont\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cont\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cont\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_lowest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'X_cont' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "from sklearn.preprocessing import Imputer\n",
      "import numpy as np\n",
      "from pandas import isnull, Categorical\n",
      "\n",
      "X = train.copy()\n",
      "test = test1.copy()\n",
      "## convert response to matrix right away\n",
      "y = train['Survived']\n",
      "# extract title\n",
      "X['Title'] = X.Name.apply(lambda x: title(x))\n",
      "test['Title'] = X.Name.apply(lambda x: title(x))\n",
      "\n",
      "age_by_group = X.groupby('Title').Age.mean()\n",
      "X['Age'] = X.apply(lambda x: impute(x, age_by_group), axis=1)\n",
      "#X['Child'] = X.apply(lambda x: 1 if x['Age'] < 12 else 0, axis=1)\n",
      "X['FamilySize'] = X.apply(lambda x: x['Parch'] + x['SibSp'] + 1, axis=1)\n",
      "#X['Mother'] = X.apply(lambda x: 1 if x['Title'] == 2 and x['Parch'] > 0 else 0, axis=1)\n",
      "X['FamilyId'] = X.apply(lambda x: '{}{}'.format(x.FamilySize, x.Name.split(',')[0]), axis=1)\n",
      "X.ix[X.FamilySize <= 2, 'FamilyId'] = 'Small'\n",
      "fids = X.groupby('FamilyId').FamilyId.apply(lambda x: len(x))\n",
      "fids = fids[fids <= 2 ]\n",
      "X.ix[X.FamilyId.isin(fids), 'FamilyId'] = 'Small'\n",
      "\n",
      "test['Age'] = test.apply(lambda x: impute(x, age_by_group), axis=1)\n",
      "#test['Child'] = test.apply(lambda x: 1 if x['Age'] < 12 else 0, axis=1)\n",
      "test['FamilySize'] = test.apply(lambda x: x['Parch'] + x['SibSp'] + 1, axis=1)\n",
      "#test['Mother'] = test.apply(lambda x: 1 if x['Title'] == 2 and x['Parch'] > 0 else 0, axis=1)\n",
      "test['FamilyId'] = test.apply(lambda x: '{}{}'.format(x.FamilySize, x.Name.split(',')[0]), axis=1)\n",
      "test.ix[test.FamilySize <= 2, 'FamilyId'] = 'Small'\n",
      "fids = test.groupby('FamilyId').FamilyId.apply(lambda x: len(x))\n",
      "fids = fids[fids <= 2 ]\n",
      "test.ix[test.FamilyId.isin(fids), 'FamilyId'] = 'Small'\n",
      "\n",
      "# # we don't work with these features, can drop them\n",
      "X = X.drop(['Survived', 'PassengerId', 'Name', 'Embarked', 'Ticket', 'Cabin'], axis=1)\n",
      "test = test.drop(['PassengerId', 'Name', 'Embarked', 'Ticket', 'Cabin'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## split out categorical features from continuous, makes processing easier\n",
      "X_categ = X[['Sex', 'Pclass', 'Title', 'FamilyId']]\n",
      "test_categ = test[['Sex', 'Pclass', 'Title', 'FamilyId']]\n",
      "X_cont = X[['Age', 'Fare', 'FamilySize']]\n",
      "test_cont = test[['Age', 'Fare', 'FamilySize']]\n",
      "\n",
      "familyid = dict(izip(X.FamilyId.unique(), xrange(len(X.FamilyId.unique()))))\n",
      "l = len(familyid.keys())\n",
      "\n",
      "## convert categories into integers\n",
      "X_categ['Sex'] = X_categ.Sex.apply(lambda x: mf(x))\n",
      "X_categ['Pclass']  =  X_categ.Pclass.apply(lambda x: pclass(x))\n",
      "X_categ['FamilyId'] = X_categ.FamilyId.apply(lambda x: familyid.get(x, l))\n",
      "# X_categ['Embarked']  =  X_categ.Embarked.apply(lambda x: embarked(x))\n",
      "# X_categ['Ticket']  =  X_categ.Ticket.apply(lambda x: ticket.get(x, 681))\n",
      "# X_categ['Cabin']  =  X_categ.Cabin.apply(lambda x: cabin.get(x, 148))\n",
      "test_categ['Sex'] = test_categ.Sex.apply(lambda x: mf(x))\n",
      "test_categ['Pclass'] =  test_categ.Pclass.apply(lambda x: pclass(x))\n",
      "test_categ['FamilyId'] = test_categ.FamilyId.apply(lambda x: familyid.get(x, l))\n",
      "# test_categ['Embarked'] =  test_categ.Embarked.apply(lambda x: embarked(x))\n",
      "# test_categ['Ticket'] =  test_categ.Ticket.apply(lambda x: ticket.get(x, 681))\n",
      "# test_categ['Cabin'] =  test_categ.Cabin.apply(lambda x: cabin.get(x, 148))\n",
      "\n",
      "## convert to matrices from DataFrame, some exceptions arise otherwise\n",
      "X_cont = X_cont.as_matrix()\n",
      "test_cont = test_cont.as_matrix()\n",
      "X_categ = X_categ.as_matrix()\n",
      "test_categ = test_categ.as_matrix()\n",
      "\n",
      "\n",
      "## scikit-lear can't handle missing data, so imput, consider PCA, not a mean\n",
      "# column 0 is Age, column 1 is Fare\n",
      "# Fare only has NaN values in the test set\n",
      "#imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
      "imp2 = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
      "#imp.fit(X_cont[0::, 0])\n",
      "#X_cont[0::, 0][isnull(X_cont[0::, 0])] = imp.transform(X_cont[0::, 0])\n",
      "                 \n",
      "#imp.fit(test_cont[0::, 0])\n",
      "#test_cont[0::, 0][isnull(test_cont[0::, 0])] = imp.transform(test_cont[0::, 0])\n",
      "imp2.fit(test_cont[0::, 1])\n",
      "test_cont[0::, 1][isnull(test_cont[0::, 1])] = imp2.transform(test_cont[0::, 1])\n",
      "\n",
      "\n",
      "## standardizaton\n",
      "scaler = preprocessing.StandardScaler().fit(X_cont)\n",
      "X_cont = scaler.transform(X_cont)\n",
      "test_cont = scaler.transform(test_cont)\n",
      "\n",
      "\n",
      "# scikit-learn will treat features encoded as integers, will treat them as continuous variables\n",
      "# this step will encode features with m possible values into m binary features\n",
      "# n_values is specified because one observation is missing for the Embarked feature in training set\n",
      "# n_values=[3, 4, 4, 682, 149] # with ticket and cabin\n",
      "enc = preprocessing.OneHotEncoder(n_values=[2, 3, 8, l+1])\n",
      "enc.fit(X_categ)\n",
      "X_categ = enc.transform(X_categ).toarray()\n",
      "enc.fit(test_categ)\n",
      "test_categ = enc.transform(test_categ).toarray()\n",
      "\n",
      "\n",
      "## This is probably not needed, ends up encoded the same way, would be useful for num labels > 2\n",
      "# le = preprocessing.LabelEncoder()\n",
      "# le.fit(y)\n",
      "# y = le.transform(y)\n",
      "\n",
      "\n",
      "## concatenate the processed matrices\n",
      "X = np.c_[X_categ, X_cont]\n",
      "test = np.c_[test_categ, test_cont]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import sem\n",
      "\n",
      "def mean_score(scores):\n",
      "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
      "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
      "        np.mean(scores), sem(scores))\n",
      "\n",
      "def display_scores(params, scores, append_star=False):\n",
      "    \"\"\"Format the mean score +/- std error for params\"\"\"\n",
      "    params = \", \".join(\"{0}={1}\".format(k, v)\n",
      "                      for k, v in params.items())\n",
      "    line = \"{0}:\\t{1:.3f} (+/-{2:.3f})\".format(\n",
      "        params, np.mean(scores), sem(scores))\n",
      "    if append_star:\n",
      "        line += \" *\"\n",
      "    return line\n",
      "\n",
      "def display_grid_scores(grid_scores, top=None):\n",
      "    \"\"\"Helper function to format a report on a grid of scores\"\"\"\n",
      "    \n",
      "    grid_scores = sorted(grid_scores, key=lambda x: x[1], reverse=True)\n",
      "    if top is not None:\n",
      "        grid_scores = grid_scores[:top]\n",
      "        \n",
      "    # Compute a threshold for staring models with overlapping\n",
      "    # stderr:\n",
      "    _, best_mean, best_scores = grid_scores[0]\n",
      "    threshold = best_mean - 2 * sem(best_scores)\n",
      "    \n",
      "    for params, mean_score, scores in grid_scores:\n",
      "        append_star = mean_score + 2 * sem(scores) > threshold\n",
      "        print(display_scores(params, scores, append_star=append_star))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "n_samples, n_features = X.shape\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    X, y, test_size=0.25, random_state=0)\n",
      "\n",
      "print(\"n_samples=%d\" % n_samples)\n",
      "print(\"n_features=%d\" % n_features)\n",
      "\n",
      "print(\"train data shape: %r, train target shape: %r\"\n",
      "      % (X_train.shape, y_train.shape))\n",
      "print(\"test data shape: %r, test target shape: %r\"\n",
      "      % (X_test.shape, y_test.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "n_samples=891\n",
        "n_features=104\n",
        "train data shape: (668L, 104L), train target shape: (668L,)\n",
        "test data shape: (223L, 104L), test target shape: (223L,)\n"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "tree_params = {\n",
      "    'criterion': ['gini', 'entropy'],\n",
      "    'min_samples_split': [2, 10, 20],\n",
      "    'max_depth': [5, 7, 20, 50, None],\n",
      "    'bootstrap': [True],\n",
      "    #'oob_score': [True],\n",
      "}\n",
      "\n",
      "n_subsamples = 500\n",
      "\n",
      "print(ExtraTreesClassifier())\n",
      "#ExtraTreesClassifier?\n",
      "\n",
      "trees = ExtraTreesClassifier( n_estimators=300)\n",
      "\n",
      "cv = ShuffleSplit(n_subsamples, n_iter=5, test_size=0.1)\n",
      "gs_trees = GridSearchCV(trees, tree_params, n_jobs=-1, cv=cv)\n",
      "#%time \n",
      "gs_trees.fit(X_train, y_train)\n",
      "display_grid_scores(gs_trees.grid_scores_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ExtraTreesClassifier(bootstrap=False, compute_importances=None,\n",
        "           criterion=gini, max_depth=None, max_features=auto,\n",
        "           min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
        "           verbose=0)\n",
        "min_samples_split=2, bootstrap=True, criterion=gini, max_depth=7:\t0.868 (+/-0.016) *"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_split=2, bootstrap=True, criterion=entropy, max_depth=20:\t0.860 (+/-0.019) *\n",
        "min_samples_split=2, bootstrap=True, criterion=entropy, max_depth=50:\t0.860 (+/-0.020) *\n",
        "min_samples_split=2, bootstrap=True, criterion=gini, max_depth=20:\t0.852 (+/-0.025) *\n",
        "min_samples_split=10, bootstrap=True, criterion=gini, max_depth=None:\t0.848 (+/-0.020) *\n",
        "min_samples_split=20, bootstrap=True, criterion=entropy, max_depth=None:\t0.848 (+/-0.027) *\n",
        "min_samples_split=2, bootstrap=True, criterion=gini, max_depth=50:\t0.840 (+/-0.023) *\n",
        "min_samples_split=2, bootstrap=True, criterion=gini, max_depth=5:\t0.836 (+/-0.016) *\n",
        "min_samples_split=20, bootstrap=True, criterion=gini, max_depth=50:\t0.836 (+/-0.012) *\n",
        "min_samples_split=2, bootstrap=True, criterion=gini, max_depth=None:\t0.836 (+/-0.010) *\n",
        "min_samples_split=20, bootstrap=True, criterion=gini, max_depth=20:\t0.832 (+/-0.034) *\n",
        "min_samples_split=10, bootstrap=True, criterion=entropy, max_depth=5:\t0.828 (+/-0.027) *\n",
        "min_samples_split=10, bootstrap=True, criterion=gini, max_depth=20:\t0.824 (+/-0.010) *\n",
        "min_samples_split=10, bootstrap=True, criterion=entropy, max_depth=None:\t0.820 (+/-0.028) *\n",
        "min_samples_split=10, bootstrap=True, criterion=gini, max_depth=5:\t0.816 (+/-0.021) *\n",
        "min_samples_split=10, bootstrap=True, criterion=gini, max_depth=7:\t0.816 (+/-0.012) *\n",
        "min_samples_split=10, bootstrap=True, criterion=gini, max_depth=50:\t0.816 (+/-0.032) *\n",
        "min_samples_split=20, bootstrap=True, criterion=gini, max_depth=None:\t0.816 (+/-0.016) *\n",
        "min_samples_split=10, bootstrap=True, criterion=entropy, max_depth=7:\t0.816 (+/-0.034) *\n",
        "min_samples_split=20, bootstrap=True, criterion=entropy, max_depth=7:\t0.816 (+/-0.033) *\n",
        "min_samples_split=20, bootstrap=True, criterion=entropy, max_depth=50:\t0.816 (+/-0.016) *\n",
        "min_samples_split=2, bootstrap=True, criterion=entropy, max_depth=None:\t0.812 (+/-0.016) *\n",
        "min_samples_split=2, bootstrap=True, criterion=entropy, max_depth=5:\t0.804 (+/-0.029) *\n",
        "min_samples_split=2, bootstrap=True, criterion=entropy, max_depth=7:\t0.800 (+/-0.035) *\n",
        "min_samples_split=20, bootstrap=True, criterion=entropy, max_depth=5:\t0.796 (+/-0.013)\n",
        "min_samples_split=20, bootstrap=True, criterion=gini, max_depth=7:\t0.792 (+/-0.014)\n",
        "min_samples_split=20, bootstrap=True, criterion=gini, max_depth=5:\t0.788 (+/-0.038) *\n",
        "min_samples_split=10, bootstrap=True, criterion=entropy, max_depth=20:\t0.784 (+/-0.035) *\n",
        "min_samples_split=10, bootstrap=True, criterion=entropy, max_depth=50:\t0.784 (+/-0.022)\n",
        "min_samples_split=20, bootstrap=True, criterion=entropy, max_depth=20:\t0.768 (+/-0.022)\n"
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Careful with the interpretation, this subsets were trained on"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg_trees = ExtraTreesClassifier(n_estimators=50, max_depth=6, min_samples_split=10)\n",
      "reg_trees.fit(X_train, y_train)\n",
      "print(\"Train score: %0.3f\" % reg_trees.score(X_train, y_train))\n",
      "print(\"Test score: %0.3f\" % reg_trees.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train score: 0.865\n",
        "Test score: 0.821\n"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = reg_trees.predict(test)\n",
      "#pred = gs_trees.best_estimator_.predict(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "\n",
      "pred = pred.astype(numpy.int64)\n",
      "df = DataFrame(data={'Survived': pred, 'PassengerId': test1['PassengerId']})\n",
      "df = df.ix[:,['Survived', 'PassengerId']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df.to_csv('../../../data/predicted/extra_tree_classifier-0.984.txt', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import merge\n",
      "\n",
      "d = merge(df, test2, on='PassengerId')[['Survived_x', 'Survived_y']]\n",
      "(d['Survived_x'] == d['Survived_y']).apply(lambda x: 1 if x else 0).sum() * 1.0 / d.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 243,
       "text": [
        "0.73444976076555024"
       ]
      }
     ],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "tree_params = {\n",
      "    'criterion': ['gini', 'entropy'],\n",
      "    'min_samples_split': [2, 10, 20],\n",
      "    'max_depth': [5, 7, 20, 50, None],\n",
      "    'oob_score': [True]\n",
      "}\n",
      "\n",
      "n_subsamples = 500\n",
      "\n",
      "print(RandomForestClassifier())\n",
      "#ExtraTreesClassifier?\n",
      "\n",
      "trees = RandomForestClassifier(n_estimators=30)\n",
      "\n",
      "cv = ShuffleSplit(n_subsamples, n_iter=5, test_size=0.1)\n",
      "gs_trees = GridSearchCV(trees, tree_params, n_jobs=-1, cv=cv)\n",
      "#%time \n",
      "gs_trees.fit(X, y)\n",
      "display_grid_scores(gs_trees.grid_scores_)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion=gini, max_depth=None, max_features=auto,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
        "            verbose=0)\n",
        "min_samples_split=2, oob_score=True, criterion=entropy, max_depth=5:\t0.884 (+/-0.010) *"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_split=20, oob_score=True, criterion=gini, max_depth=None:\t0.872 (+/-0.026) *\n",
        "min_samples_split=20, oob_score=True, criterion=entropy, max_depth=7:\t0.860 (+/-0.014) *\n",
        "min_samples_split=10, oob_score=True, criterion=gini, max_depth=5:\t0.848 (+/-0.028) *\n",
        "min_samples_split=10, oob_score=True, criterion=entropy, max_depth=7:\t0.848 (+/-0.029) *\n",
        "min_samples_split=10, oob_score=True, criterion=entropy, max_depth=50:\t0.848 (+/-0.016) *\n",
        "min_samples_split=10, oob_score=True, criterion=entropy, max_depth=None:\t0.848 (+/-0.019) *\n",
        "min_samples_split=20, oob_score=True, criterion=entropy, max_depth=50:\t0.840 (+/-0.020) *\n",
        "min_samples_split=2, oob_score=True, criterion=entropy, max_depth=7:\t0.836 (+/-0.017) *\n",
        "min_samples_split=20, oob_score=True, criterion=gini, max_depth=20:\t0.832 (+/-0.041) *\n",
        "min_samples_split=20, oob_score=True, criterion=gini, max_depth=50:\t0.832 (+/-0.012)\n",
        "min_samples_split=2, oob_score=True, criterion=gini, max_depth=None:\t0.832 (+/-0.010)\n",
        "min_samples_split=2, oob_score=True, criterion=gini, max_depth=7:\t0.824 (+/-0.019)\n",
        "min_samples_split=10, oob_score=True, criterion=entropy, max_depth=20:\t0.824 (+/-0.007)\n",
        "min_samples_split=20, oob_score=True, criterion=gini, max_depth=7:\t0.816 (+/-0.025) *\n",
        "min_samples_split=20, oob_score=True, criterion=entropy, max_depth=20:\t0.816 (+/-0.042) *\n",
        "min_samples_split=10, oob_score=True, criterion=gini, max_depth=7:\t0.812 (+/-0.016)\n",
        "min_samples_split=10, oob_score=True, criterion=gini, max_depth=50:\t0.812 (+/-0.020)\n",
        "min_samples_split=2, oob_score=True, criterion=entropy, max_depth=50:\t0.812 (+/-0.021)\n",
        "min_samples_split=10, oob_score=True, criterion=entropy, max_depth=5:\t0.808 (+/-0.019)\n",
        "min_samples_split=2, oob_score=True, criterion=entropy, max_depth=None:\t0.808 (+/-0.014)\n",
        "min_samples_split=2, oob_score=True, criterion=gini, max_depth=50:\t0.796 (+/-0.012)\n",
        "min_samples_split=10, oob_score=True, criterion=gini, max_depth=None:\t0.796 (+/-0.018)\n",
        "min_samples_split=2, oob_score=True, criterion=gini, max_depth=5:\t0.792 (+/-0.014)\n",
        "min_samples_split=20, oob_score=True, criterion=gini, max_depth=5:\t0.792 (+/-0.022)\n",
        "min_samples_split=2, oob_score=True, criterion=gini, max_depth=20:\t0.792 (+/-0.034)\n",
        "min_samples_split=10, oob_score=True, criterion=gini, max_depth=20:\t0.788 (+/-0.019)\n",
        "min_samples_split=2, oob_score=True, criterion=entropy, max_depth=20:\t0.788 (+/-0.029)\n",
        "min_samples_split=20, oob_score=True, criterion=entropy, max_depth=5:\t0.752 (+/-0.022)\n",
        "min_samples_split=20, oob_score=True, criterion=entropy, max_depth=None:\t0.740 (+/-0.030)\n"
       ]
      }
     ],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = RandomForestClassifier(n_estimators=30, **gs_trees.best_params_)\n",
      "pred.fit(X, y)\n",
      "pred = pred.predict(test)\n",
      "\n",
      "#pred = pred.astype(numpy.int64)\n",
      "\n",
      "df = DataFrame(data={'Survived': pred, 'PassengerId': test1['PassengerId']})\n",
      "df = df.ix[:,['Survived', 'PassengerId']]\n",
      "d = merge(df, test2, on='PassengerId')[['Survived_x', 'Survived_y']]\n",
      "(d['Survived_x'] == d['Survived_y']).apply(lambda x: 1 if x else 0).sum() * 1.0 / d.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 289,
       "text": [
        "0.76315789473684215"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    }
   ],
   "metadata": {}
  }
 ]
}